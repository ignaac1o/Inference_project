---
title: "Inference_project"
author: Ignacio Almodóar & Limingrui Wan
output: pdf_document
---


\newpage

# 1. Introduction 

## 1.1 Description of the project and motivation. 

The aim of this project is to garner knowledge in the vehicles market, specifically about electric vehicles, which is a segment that is growing year by year.

The electric vehicle market has grown a lot in the last years. Each year different brands are releasing new models with different specs and capacities. The automobile industry has been around us for almost 130 years, which means that almost everybody has at least a little bit of knowledge about the market in terms of traditional cars (combustion engines), if not, probably people around you (relatives or friends) might know enough to give you recommendations that suits your needs.

However, what about electric cars? Most people struggle even telling prices for models that have already been in the market for more than five years, like Model S from Tesla or BMW i3, which are probably the ones that most people have seen several times on the streets, specially if you live in the city center.

As electric cars have always had that label of "expensive cars" or "useless noways", people still do not have the necessity to start considering them as feasible options to buy when looking for a new car, which ends up with an uninformed society when it comes to this "new age" of cars.

Nevertheless, this mentality has been changing, specially in the last few years. It is not difficult to see several electric cars in one day, which means that people are starting to care about electric cars and to learn about them. However, it is sometimes difficult to compare between electric cars and traditional ones, because it is not part of what people are used to, and the prices might vary a lot for different models that might look the same by just looking at the specs. Also, as new brands have come, many people do not know if their products are worth the price or not.

That being said, we have considered that this study could be useful for both companies and consumers. On one hand, companies that want to start developing electric cars might find helpful this study in order to consider several aspects while designing an electric car in terms of prices and characteristics. On the other hand, for those consumers who want to take a peek into the electric cars market, allowing them to compare different prices in terms of power, efficiency or even number of seats and to see where those prices are going while the markets grows.

If you want to take the research on electric vehicles to the next level, the information that is given in this study might be very useful in order to compare between the traditional car market and the electric one. Also, you could even make predictions about prices for the next years and which aspects are significantly evolving.

## 1.2 Description of the data set

This data set has been taken from [kaggle](https://www.kaggle.com), which is a sourced platform for data scientists from all around the world that want to solve data science, machine learning and predictive analytics problems. It has more than one million of members, whereas more than half of the community are active members.

Kaggle enables data scientists and other developers to take part in running machine learning contests, write and share scripts, and to host different data sets.

Even though we have taken the set from Kaggle, all the data that contains this data set is scrapped from an online electric cars gauge web [Electric Vehicle Database](https://ev-database.org/#sort:path~type~order=.rank~number~desc|range-slider-range:prev~next=0~1200|range-slider-acceleration:prev~next=2~23|range-slider-topspeed:prev~next=110~450|range-slider-battery:prev~next=10~200|range-slider-eff:prev~next=100~300|range-slider-fastcharge:prev~next=0~1500|paging:currentPage=0|paging:number=9), where you have different sections for finding and compare different electric vehicles.

The information contained in the data set was uploaded 2 months ago. The only information from our data set that could change over time are the prices. As the data has been updated recently, we can still consider that those are the current market prices for each car.

This data set originally contains 177 different car models with 11 different aspects for each of them. These aspects are considered the most relevant ones while searching for information of different electric cars. These are also the ones that are directly related to the price and the ones that can be easily compared to one or another.   

## 1.3 Population of our sample size 

While searching through the web from where this data set has been scrapped, you can see that they have different sections for electric cars:

- Most recent
- Cheapest EV
- Most Efficient
- Quickest 0-100
- Longest range

In our case we have taken the ones listed for the cheapest electric car vehicles section, which necessary do not have only cheap cars, however it might show the most affordable ones from the ones with similar characteristics. Also it shows the most basic configuration for each model, so it basically shows the price from which you can get the most basic model.

Notice that this data set is continuously updating, which means that you might get different results depending on when you do your research.

In short, we can consider that our population is the whole electric brand new market, whereas our sample is a summary of those who are considered the cheapest ones.

## 1.4 Description of the variables

As we have mentioned, this data set contains eleven columns which basically tells us the most important aspects for every car.

On each of these different columns we will find different types of variables, some of them might be continuous, some others might be discrete with very few possible values, where ass others are discrete with a higher range of values.

On the other hand we have some of them that does not gives us much information or are difficult to understand if you are not very much into electric cars.

In essence, these are the variables that our data set contains:

- Name: This variable contains each car model name, including the brand and the exact model. This column strictly consists on string values, so we are not going to apply inference directly on it.

- Subtitle: Indicates the type of car and the capacity of the battery. The capacity of the batteries is measured in kWh, which is a unit of energy equal to one kilowatt of power sustained for one hour.

- Acceleration: Measures the time (in seconds) necessary for the model to accelerate from 0-100km/h. This is always a good indicator about the power that the engine provides in relation to the car weight. It is a continuous variable with range between 2.1 and 22.4 seconds.

- TopSpeed: Shows the maximum speed that the vehicle can reach. It is measured in Km/h and it shows how well does the car leverages the potential of its batteries. It is also a continuous variable with values between 123 and 410 km/h.

- Range: Shows the approximate distance a vehicle can travel with a 100% charge, which is always a good indicator about the real capacity of the batteries that the vehicle has in terms of common-daily use. It is measured in km and it is a continuous variable with range 95-970 km.

- Efficiency: This is a relatively difficult variable to understand. It calculates the battery energy consumption used by the vehicle for propulsion and on-board systems, which basically tells us the average consumption of energy per kilometers. This could be easily compared as the average liters per kilometer consumption of fuel for a combustion engine powered car. It is a continuous variable measured in Wh/km. Its range is 104-281 Wh/km

- FastChargeSpeed:This is also a strange variable because it is measured in km/h and it rates the average charging speed over a session from 10% to 80%. It is a continuous variable that fluctuates between 0 and 980 km/h for 0 meaning that it does not have fast charge mode.

- Drive: It defines which pair of wheels are the driving wheels of the vehicle, which is a very important attribute while buying a car. It is a discrete variable with three values (front wheel, Rear wheel and all wheel)

- NumberOfSeats: Indicates the number of legally seats available in the car. It is a discrete variable that oscillates between 2 and 7.

- PriceinGermany: It shows the retail price un Germany for a brand new model. It is a continuous variable and it is measured in Euros. The prices vary between 18460 and 215000 €.

- PriceinUKs: Same concept as before whereas in this case it for UK and it is measured in pounds. Notice that it is not strictly the conversion between euros and pounds, for most of them, the price will be higher in the UK.

This is a resume of all the variables that our data set contains. However we might not use some of them in this project as the information that they provide might not be very useful for the conclusions that we want to reach. Due to this, we might filter our data set in order to use only the columns that we find interesting.

\newpage

# 2. Model Selection

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
data=read.csv("EV_DATASET_woNA.csv",dec = ",")
data$PriceinGermany[is.na(data$PriceinGermany)]=data$PriceinUK[is.na(data$PriceinGermany)]*1.15
data=data[-c(29,120,129),]
data$PriceinGermany=data$PriceinGermany*1000
l_data=length(data$PriceinGermany)
```


## 2.1 Probability distribuction of our continuous random variable "Price in Germany"

In order to get a quick view of how our variable is distributed, we have to plot it. A good way to view it is by plotting a histogram of the variable.

```{r echo=FALSE}
EURprice=data$PriceinGermany
```

```{r echo=FALSE}
pricelog=log(EURprice)
par(mfrow=c(1,2))
hist(EURprice)
hist(pricelog,prob=TRUE)
```

By analyzing this plot we can assume that it follows a gamma distribution $\Gamma(\alpha,\lambda)$. We are also going to transform our data applying logarithms to it and see if its shape can be estimated as a normal.

Applying logarithm we get a much symmetric distribution, that can be considered as a normal distribution.

Given this results we can consider that our variable "PriceforGermany" follows a gamma distribution, whereas applying logarithm transformation to it makes it look more like a normal distribution.

## 2.2 Estimation of model parameters.

In this point we are going to estimate our model parameters for our variable "PriceforGermany" with and without the logarithm transformation in order to know which one is better estimated

We have assumed that our random variable "PriceforGermany" follows a gamma distribution $\Gamma(\alpha,\lambda)$ with parameters:

- Shape $k$, $\alpha=k$
- Scale $\theta$, $\lambda=\frac{1}{\theta}$ 

As we want to estimate our model parameters $\hat{\alpha}$ and $\hat{\lambda}$, we are going to use the method of moments in order estimate it.

The method of moments consists in leveling population moments and sample moments in order to get an equation or system of equations from where to get our wanted parameters.

For a gamma distribution, we get the following equations:

- $E[x]=\frac{1}{n}\sum_{i=0}^n x=\overline X$ for the fist population moment
- $E[x^2]=\frac{1}{n}\sum_{i=0}^n x_{^2}$ for the second population moment 

As we know that $E[x]=\frac{\alpha}{\lambda}$ for a Gamma distribution, from the first function we get that:

$$\alpha=\overline X\lambda$$

Replacing $\alpha$ on the second equation and simplifying it, we obtain:

$$\hat\lambda= \frac{\overline X}{\frac{1}{n}\sum_{i=0}^n x_{i}^2 - \overline{X}^2}$$

Whereas, using $\alpha=\overline X\lambda$, we get:

$$\hat\alpha=\overline X\hat\lambda=\frac{\overline X^2}{\frac{1}{n}\sum_{i=0}^n x_{i}^2 - \overline{X}^2}$$

Using these results we can calculate our estimators using R. We are going to compute the estimators of our variable. Running the code above we can say that our variable "Price in Germany" follows a $\Gamma(\hat\alpha,\hat\lambda)$ with parameters $\hat\alpha=3.3$ and $\hat\lambda=5.649*10^-5$.


For the logarithm transformation we are considering that our variable follows a normal distribution so, in order to estimate our parameters we are going yo use the Maximum Likelihood method. For this purpose we have to compute $\frac{\partial}{\partial\theta_{k}}L(\theta;x_{1},...,x_{n})=0$. This will give us a system of equations from where we can obtain each of our estimators.

Therefore, for a normal distribution we have:

$$L(\mu,\sigma^2,x_{1},...,x_{n})=\frac{1}{\sqrt(2\pi\sigma^2)}e^{(\frac{-1}{2\sigma^2}\sum_{i=1}^{n}(x_{i}-\mu)^2)}$$
Applying logarithm to the function we can simplify it.

$$l(\mu,\sigma^2,x_{1},...,x_{n})=-\frac{n}{2}log(2\pi\sigma^2)-\frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_{i}-\mu)^2)$$
As we want to obtain the maximum of the loglikelihood, we get the following system of equations:

$$\frac{\partial l}{\partial\mu}=\frac{1}{\sigma^2}\sum_{i=1}^n(x_{i}-\mu)=0 $$
$$\frac{\partial l}{\partial\sigma^2}=\frac{-n}{2\sigma^2}+\frac{\sum_{i=1}^n(x_{i}-\mu)^2}{2\sigma^4}=0 $$
Solving the system we finally get our estimators:

$$\hat\mu=\overline{x}_n$$
$$\hat\sigma=\frac{1}{n}\sum(x_i-\overline{x})^2$$
By the results obtained we can see that our estimator for $\hat\mu$ is the sample mean, whereas for $\hat\sigma$ we have the sample variance.

Within this last plot we can see that the estimated distribution for our variable "PriceforGermany" transformed with logarithm is very close to the distribution of the variable so we can consider that it follows a normal distribution. 

```{r echo=FALSE}
a=0
for(i in 1:length(EURprice)){
  a=a+EURprice[i]^2
}
hatlambda=(mean(EURprice))/((a/length(EURprice))-mean(EURprice)^2)
hatalpha=hatlambda*mean(EURprice)
par(mfrow=c(1,2))
hist(EURprice,prob=TRUE,breaks = 20)
r <- seq(min(EURprice), max(EURprice), length = 177)
f <- dgamma(r, hatalpha, hatlambda)
lines(r, f, col = "red", lwd = 2)
hatmu=mean(pricelog)
hatsigma=var(pricelog)
x=1:length(pricelog)
hist(pricelog,prob=TRUE,breaks = 20,ylim=c(0,1.5))
rlog =  seq(min(pricelog), max(pricelog), length = 177)
l <- dnorm(rlog, hatmu, sqrt(hatsigma))
lines(rlog, l, col = "red", lwd = 2)
```

\newpage 

# 3. One-sample Inference

## 3.1 Estimators for our population mean

In this section we can use sample mean and sample median value to estimate our population mean. The sample mean is 10.86,sample median is 10.82.

```{r echo=FALSE}
samplemean=mean(pricelog)
sampleva=var(pricelog)
```
We can quickly give the distribution of the sample mean considering CLT as our sample is long enough:
$$\hat\theta \sim N(\mu,\sigma^2/n)$$

Obviously the sample mean is an unbiased estimator, since $exp(samplemean)=\mu$. Meanwhile, as we assume that it's a normal distribution, it's symmetric, thus sample median value is also unbiased $exp(med)=\mu$.

However, it's not easy to obtain the real distribution of sample median value(to get the expectation and variance), firstly we get the pdf of the sample median value via the formula for ordered statistics, which is$\rho_k(x) =\frac{n!}{(k-1)!(n-k)!}(F(x))^{k-1}(1-F(x))^{n-k}\rho(x)$,
where n is the total number, k is the sequence number, $\rho(x)$ is the pdf of the original distribution(normal distribution), $F(x)$ is the cdf of the original distribution. So we shall calculate such indefinite integral to get it's expectation:$\int x\rho_k(x) \space dx$,However, so far the computation is too complex, thus we decide to use the approximated variance given in the slides and others reference
$$V(med) \approx \frac{\pi \sigma^2}{2n}$$

In order to check if the estimator is efficient, we just have to check their fisher information $I_n(\theta)=\frac {n}{\sigma^2}=v(\overline x)<v(med)$, so only sample mean is efficient.

Obviously, sample mean has smaller variance and more efficient, but median value is more robust, can afford more missing of sample or more outliers.

## 3.2 Estimation of the errors of the two estimators

Since sample mean and sample median value are both unbiased, we can calculate the error by CV, which is 
$$cv=\frac{sd(\hat \theta)}{exp(\hat \theta)} $$

$cv(mean)=0.042,cv(med)=0.066$

```{r echo=FALSE}
cv1=(hatsigma)^0.5/hatmu
cv2=cv1*1.57

```


## 3.3 Confidence interval of 95% for our population mean

In order to obtain the upper bound and the lower bound, we need to find such $c_1,c_2$ s.t.
$$P(c_1<\mu<c_2)=1-\alpha$$
We are having a normal assumption of the distribution, so we use *exact confidence intervals under normality*, and of course we can use T-statistic. Describe our problem in a mathematical way:

We have $(x_1,x_2,\dots,x_n)$ s.r.s. form a r.v. $N(\mu,\sigma^2)$, where $\mu, \sigma$unknown, and $n=177$, it holds
$$T=\frac{\overline x-\mu}{S_n'/\sqrt{n}}\sim t_{n-1}$$

then we  have to find such $t_1,t_2$ s.t.$P(t_1<T<t_2)=1-\alpha$

$$P(\frac{\overline x-c_1}{S'/\sqrt n}<\frac{\overline x-\mu}{S'/\sqrt n}<\frac{\overline x-c_2}{S'/\sqrt n})=1-\alpha$$

$$P(\frac{\overline x-c_1}{S'/\sqrt n}<T<\frac{\overline x-c_2}{S'/\sqrt n})=1-\alpha$$

$$CI_{1-\alpha}(\mu)=(\overline x +t_{n-1,\alpha/2}*\frac{S'}{\sqrt n},\overline x -t_{n-1,\alpha/2}*\frac{S'}{\sqrt n})$$
As the result, the 95% CI of population mean is (9.96,11.76)

```{r echo=FALSE}
CI=c(samplemean+qt(0.025,df=176)*sqrt(sampleva),samplemean+qt(0.975,df=176)*sqrt(sampleva))
```

Within this result we can conclude that with a 95% of confidence the population mean for prices in electric cars is between 9.96 and 11.76 in a logarithm scale.

## 3.4 Estimation of the proportion of units in the population that belongs to the category selected

We divided the sample into three groups according to the variable "drive", which implies how the specific car is driven. Considering a Binomial distribution $Bern(p)$, the estimator actually estimate the mean value of the probability in a Binomial test, so the distribution of estimated proportion is $N(p,\frac{1(1-p)}{n})$

```{r echo=FALSE}
data$Drive=as.factor(data$Drive)
```

the estimated proportion is:(0.362,0.284,0.254)

```{r echo=FALSE}
p1=64/177
p2=68/177
p3=45/177
```

## 3.5 Variance of our estimator of proportion

Since we have obtained the distribution of $\overline x$,we can easily get the variance of the estimator:(0.0013,0.0013,0.0011)

```{r echo=FALSE}
v1=p1*(1-p1)/l_data
v2=p2*(1-p2)/l_data
v3=p3*(1-p3)/l_data
```
## 3.6 Population proportion with 95% of confidence interval

From our previous work, we notice that the proportion actually is $\overline x=\hat p$, and with CLT we can give it's distribution
$\overline x \sim N(\hat p,\frac{\hat p(1-\hat p)}{n})$,

so we have:
$$\frac{\overline x-p}{\sqrt{p(1-p)/n}}\stackrel{d}\longrightarrow N(0,1)$$
$$\sqrt{\frac{\overline x(1-\overline x)}{p(1-p)}}\stackrel{p}\longrightarrow 1$$
Combining above two lines, and according to the Slutsky' th :
$$Z=\frac{\overline x-p}{\sqrt{\frac{\overline x(1-\overline x)}{n}}}\stackrel{d}\longrightarrow N(0,1)$$
so now we only need to find such $c_1,c_2 \space s.t.$
$$P(c_1<=p<=c2)=1-\alpha$$
$$P(\frac{\overline x-c_1}{\sqrt{\frac{\overline x(1-\overline x)}{n}}}<=Z<=\frac{\overline x-c_2}{\sqrt{\frac{\overline x(1-\overline x)}{n}}})=1-\alpha$$

$$\hat p \pm Z_{\alpha/2} \sqrt{\frac{\hat p(1-\hat p)}{n}}$$
and the intervals of three proportions are: all wheel driven cars (0.29,0.43),front wheel driven cars(0.31,0.46),rear wheel driven cars (0.19,0.31)

```{r echo=FALSE}
ci_p1=c(p1+qnorm(0.025)*sqrt(v1),p1-qnorm(0.025)*sqrt(v1))
ci_p2=c(p2+qnorm(0.025)*sqrt(v2),p2-qnorm(0.025)*sqrt(v2))
ci_p3=c(p3+qnorm(0.025)*sqrt(v3),p3-qnorm(0.025)*sqrt(v3))
```

\newpage


# 4 Inference with more than one sample

```{r echo=FALSE}
data$size=1
data$size[data$NumberofSeats!=7]=0
data_smallcar=data[data$size==0,]
data_bigcar=data[data$size==1,]
```

## 4.1 population mean of each group

In this section, we choose to divide the sample and population into two subgroups according to the variable *numberofseats*. This variable has four possible values :2,4,5,7. But we can notice that some subgroups have only a few items, so we decide to create a new factor variable *size*. We defined the cars with 5 or less seats as *small* cars, marked with *0*, and the cars with 7 seats as *big* cars, marked with *1*.

There are 145 small cars and 32 big cars in the sample, and we assume for each subgroup the distribution is still normal.  

In general, the case could be describe mathematically as: There is a s.r.s. $(x_{11},x_{12} ,\dots,x_{1n_1})$ from $X_1 \sim N(\mu_1,\sigma_1)$ , and another s.r.s. $(x_{21},x_{22},\dots,x_{2n_2})$ from $X_2 N(\mu_2,\sigma_2)$, where $n_1=145, n_2=32$,$\mu_1,\mu_2,\sigma_1,\sigma_2$ unknown. $X_1,X_2$ independent. 

We can estimate the population mean of *price* in our data, as we did in section 3.1, using sample mean as estimator.

$$\hat\mu_1=\overline x_1=10.84, \space\hat\mu_2=\overline x_2=10.98 $$

```{r echo=FALSE}
n1=length(data_smallcar$PriceinGermany)
n2=length(data_bigcar$PriceinGermany)
samplemean_s=mean(data_smallcar$PriceinGermany)
samplemean_b=mean(data_bigcar$PriceinGermany)
```

In order to get the coefficient of variation, we need to know the variance of the estimator, we can use $S'^2$ to estimate the population variance.

```{r echo=FALSE}
var_1=0
for (i in 1:n1){
  var_1=var_1+((samplemean_s-data_smallcar$PriceinGermany[i])^2)
}
var_1=var_1/(n1-1)

var_2=0
for (i in 1:n2){
  var_2=var_2+((samplemean_b-data_bigcar$PriceinGermany[i])^2)
}
var_2=var_2/(n1-1)
paste("estimated variance of price in small cars is ", var_1)
paste("estimated variance of price in big cars is", var_2)
```

so far we give the distribution of our estimator and compute their CVs: $\hat\mu_1 \sim N(10.84,0.24),\hat\mu_2 \sim N(10.98,0.01)$, $cv(\hat\mu_1)=0.0037,cv(\hat\mu_2)=0.0016$.

## 4.2 Estimate the proportion of Section 3.4 for each population considered in 4.1. Estimate MSE of your estimators.

Similarly, we also consider a binomial test and then apply CLT to get the estimated proportion.
The estimated proportions in big-car subgroups are: all-wheel 0.22, front-wheel 0.75, rear wheel 0.03.In small-car subgroup: all-wheel 0.393,front-wheel 0.303,rear-wheel 0.303.

Considering sample mean is an unbiased estimator for population mean, $MSE(\hat p)= B^2(\hat p)+V(\hat p)=0+V(\hat p)=V(\hat p)$. As shown in section 3.4 $V(\hat p)=\frac{\hat p(1-\hat p)}{n}$, where n is the sample size. so we have $cv_{bigcar}(\hat p _{1,2,3} )=(0.0053,0.0059,0.0009),cv_{smallcxar}(\hat p_{1,2,3})=(0.0010,0.0006,0.0006)$

## 4.3 Using the two subgroups considered in 4.1. Compare the means of the continuous variable for the two subgroups by means of a confidence interval for the difference of means.

We have now two random samples, one with all the cars that have 5 or less seats and another one formed by all the cars that have more than 7 seats. As these are random samples we do not know each population mean and variance.

In order to solve the problem we have to find a pivotal quantity where all the values in it are known. For this reason we are going to use de T statistics where mean and variances are estimated as sample means and sample cuasivariances.

$$T=\frac{\overline X_{1}-\overline{X}_2- (\mu_{1}-\mu_{2})}{\sqrt{\frac{S´_1^2}{n_1}+\frac{S´_2^2}{n_2}}} \sim t_v $$
This expression can be considered as a normal due to the Welch-Sattertwaite method  [[1](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/PASS/Confidence_Intervals_for_the_Difference_Between_Two_Means.pdf),
 [2](https://en.wikipedia.org/wiki/Welch–Satterthwaite_equation)], which is used to calculate an approximation to the effective degrees of freedom of a linear combination of independent sample variances. Using this method, we get the following expression for the degrees of freedom: 

$$v=\frac{(\frac{S´_1^2}{n_1}+\frac{S´_2^2}{n_2})^2}{\frac{S´_1^4}{n_1^2(n_1-1)}+\frac{S´_2^4}{n_2^2(n_2-1)}}$$
Now that we have our pivotal quantity we have to find our confidence intervals such that $P(c_1\leq T \leq c_2) = 1- \alpha$. Within a few changes our expression to calculate confidence intervals ends up being:

$$CI_{1-\alpha}(\mu_1-\mu_2)= \overline X_1 + \overline X_2 \pm t_{v,\alpha/2}\sqrt{\frac{S´_1^2}{n_1}+\frac{S´_2^2}{n_2}}$$
Then, a confidence interval for $\mu_1-\mu_2$ at a confidence level of 0.95 is:
```{r, echo = FALSE}
sm1=mean(data_smallcar$PriceinGermany)
sm2=mean(data_bigcar$PriceinGermany)
sv1=var(data_smallcar$PriceinGermany)
sv2=var(data_bigcar$PriceinGermany)
n1=length(data_smallcar$PriceinGermany)
n2=length(data_bigcar$PriceinGermany)

v=(((sv1/n1)+(sv2/n2))^2)/((sv1^2/(n1^2*(n1-1)))+(sv1^2/(n1^2*(n1-1))))
alpha=0.05
t=qt(alpha/2,df=v,lower.tail = FALSE)

```
```{r echo=FALSE}
(sm1-sm2)+c(-1,1)*t*sqrt((sv1/n1)+(sv2/n2))
```

Therefore we can say that the mean price for cars with less than five seats is very similar to the ones with more than 7 seats.

## 4.4 Compare the means of the continuous variable for the two subgroups by means of hypothesis testing of equality of means.

We assume now the same two populations as in the section 4.3. We will test hypotheses about the difference of means $\mu_1-\mu_2$. We are going to test if there is any major difference in the mean for the prices of the cars in Germany depending on the number of seats at a 5% level of significance.

Denoting $\theta=\mu_1-\mu_2$ we want to test:

$H_{o}: \mu_1-\mu_2$   vs. $H_1: \mu_1 \neq \mu_2$

$H_{o}: \theta=0$ vs. $\theta: \mu_1 \neq \mu_2$

As $\sigma_1^2$ and $\sigma_2^2$ are unknowns, we define our critical region is $Cc=\{|T|>t_{v,1-\alpha/2}\}$ for $v$ denoting the degrees of freedom seen in section 4.3.

Therefore, the test statistic that we are going to use is:

$$T=\frac{\overline X_{1}-\overline{X}_2- (\mu_{1}-\mu_{2})}{\sqrt{\frac{S´_1^2}{n_1}+\frac{S´_2^2}{n_2}}}$$
```{r, echo=FALSE}
t_score=(sm1-sm2)/(sqrt((sv1/n1)+(sv2/n2)))
```

Solving both equations we get the following results, $T=-2.53$ and $t_{v,\alpha/2}=1.96$. Therefore we can see that our T value is is in the critical region. Within this result we need to reject the null hypothesis. Then we can conclude that there is a major significance difference at a 5% significance level that there is a difference between the mean of the prices for cars with less than 5 seats and more than 7.

## 4.5 Compare the proportion of Section 4.4 for the subgroups by means of a confidence interval for the difference of proportions.
First consider a general case, a s.r.s $(x_{11},x_{12},\dots,x_{1n_1})$ from $X_1\sim N(\mu_1,\sigma _1^2)$, another s.r.s$(x_{21},x_{22},\dots,x_{2n_2})$ from $X_2\sim N(\mu_2,\sigma _2^2)$, then we have $\theta =x_1+x_2 \sim(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$

In our case, from above sections we know that the proportions are independently following different normal distributions. We firstly assume a variable $\theta =p_1-p_2$, where $p_1$ represents the proportions from group *big-car*, $p_2$ represents the proportions from group *small-car*. 

$$\hat\theta \sim N(\hat p_1-\hat p_2, \frac{\hat p_1(1-\hat p_1)}{n_1}+\frac{\hat p_2(1-\hat p_2)}{n_2})$$

Then as what we have done in section 3.6, find $c_1,c_2$ s.t. $P(c_1<\theta<c_2)=1-\alpha$
similarly, we have 
$$\frac{\hat\theta-\theta}{\hat\sigma(\hat\theta) }\sim N(0,1)$$
Applying all the conclusions we have proved above, we can see that the 95% CIs are (we actually have three proportions, so we can do it for three times):

$$CI(\hat p_1-\hat p_2)=((\hat p_1-\hat p_2)+Z_{\alpha/2}\sqrt{\frac{\hat p_1(1-\hat p_1)}{n_1}+\frac{\hat p_2(1-\hat p_2)}{n_2}},(\hat p_1-\hat p_2)-Z_{\alpha/2}\sqrt{\frac{\hat p_1(1-\hat p_1)}{n_1}+\frac{\hat p_2(1-\hat p_2)}{n_2}}$$

```{r echo=FALSE}
s=sqrt(table(data_bigcar$Drive)/n2*(1-table(data_bigcar$Drive)/n2)/n2+table(data_smallcar$Drive)/n1*(1-table(data_smallcar$Drive)/n1)/n1)

print("the lower bounds of the 95% CIs are:")
table(data_bigcar$Drive)/n2-table(data_smallcar$Drive)/n1+qnorm(0.025)*s
print("the uuper bounds of the 95% CIs are:")
table(data_bigcar$Drive)/n2-table(data_smallcar$Drive)/n1-qnorm(0.025)*s
```

## 4.6 Compare the proportion of Section 4.4 for the two subgrups by means of hypothesis testing of equality of proportions.

We can adapt the definitions of general case in section 4.5 and determine the hypothesis we are using. We also assume $\theta=p_1-p_2$, if $p_1=p_2$, obviously $\theta=0$, so our null hypothesis is $H_0: \theta=0$, and the alternative hypothesis is:$H_1: \theta \ne 0$. 
$$\hat\theta \sim N(\hat p_1-\hat p_2, \frac{\hat p_1(1-\hat p_1)}{n_1}+\frac{\hat p_2(1-\hat p_2)}{n_2})$$
Since we are checking if $\theta=0$,
$$Z=\frac{\hat\theta}{\hat\sigma(\hat\theta) }\sim N(0,1)$$
We will reject the null hypothesis if $Z_{obs}<Z_{0.025} orZ{obs}>Z_{0.975}$ (means the proportions in two groups are same), otherwise we will accept the null hypothesis(means they are not same). ($\alpha=0.05$ and $Z_{0.025}=-1.96,Z_{0.975}=1.96$)

```{r echo=FALSE}
(table(data_bigcar$Drive)/n2-table(data_smallcar$Drive)/n1)/s
```

We can see that we should reject that the proportions are same, for all three types.

\newpage

# Additional analyze: using bootstrap to interpret the estimator

In section 3, we interpreted the properties of two estimators *sample mean*,*sample median value* of the population mean. Considering our sample size is large enough, we can use *CLT* to obtain the approximated distribution of *sample mean*, thus is not very hard to obtain it's properties including *unbiasedness*,*efficiency* even more.

However, as shown in section 3, is always very hard to get the exact distribution of *sample median value* ,especially without normal distribution. For this reason, we only gave the expectation and variance of the *sample median value* from some references. 

To do inference for an estimator with a complex distribution, we can try to use *bootstrap*. The *bootstrap* method mainly using the idea of *resampling*. Here is a brief introduction of this method.

Assuming we have a $s.r.s. \space (x_1,x_2,\dots,x_{1000})$ from a unknown distribution $X\sim F(.)$, similarly, we want to estimate the population mean of X by sample mean.
we first randomly choose 500 items form the whole sample, and compute the mean value and record it as $m_1$, then we repeat this step for 1000 times. Here we are having a set of sample means$(m_1,m_2,\dots,m_{1000})$, and with this new set, we can give the expectation and variance of our estimator,
$$exp(samplemean)= \overline m, var(sample mean)=var(m)$$
further more, we can sort the set $(m_1,m_2,\dots,m_{1000})$ from the least to the most, and so we can determine the upper-bound and the lower-bound with 95% quantiles (actually 2.5% and 97.5%) of the 95% confidence interval. that is:

$$CI(sample mean)=(m_{(0.025*1000)},m_{(0.975*1000)})$$
Meanwhile, if we want to estimate the sample median value, all we need to do is to compute the median value of each sub-sample.

In R, we can use the package $boostrap$, or as we are not doing a complex computation ,we can do it manually. 

```{r}
n_iteration=1000 # number of repetition
i_resample=100 # size of each subsample
vector_mean=vector()# the set of mean values
vector_median=vector()# the set of median values

for(i in 1:n_iteration){
  m=sample(EURprice,size=i_resample,replace = FALSE)
  vector_mean[i]=mean(m)
  vector_median[i]=median(m)
}
mean_exp=mean(vector_mean)
median_exp=mean(vector_median)

mean_var=var(vector_mean)
median_var=var(vector_median)
```

We can visualize these two vectors:

```{r echo=FALSE}
par(mfrow=c(1,2))
hist(vector_mean)
hist(vector_median)
```

This way we obtained two estimator of population mean by $bootstrap$ methods. And we can give their expectations and variances
```{r echo=FALSE}
paste("the expectation of sample mean is:", mean_exp)
paste("the expectation of sample median is:", median_exp)
paste("the variance of the sample mean is:",mean_var)
paste("the variance of the sample median is:",median_var)
```

To obtain their confidence intervals, we need to reorganize the vectors and get the quantiles

```{r}
mean_ordered=sort(vector_mean)
median_ordered=sort(vector_median)

upper_mean=mean_ordered[975]
lower_mean=mean_ordered[25]
## confidence interval bounds of sample mean
upper_med=median_ordered[975]
lower_med=median_ordered[25]
## confidence interval bounds of sample median
```

Thus we have the estimators' 95% confidence intervals:
  ```{r echo=FALSE}
print("the 95% CI of sample mean is: ")
c(lower_mean,upper_mean)

print("the 95% CI of sample median is:")
c(lower_med,upper_med)
```

We can see that there is an obvious difference between the expectations, and the variance of sample means is larger, that is to say, more scattered.

\newpage

# Conclusions

## Summarize and comment on the most important conclusions of your analyses

At this point of the project that we can summarize all the work that we have done, we can say that the results obtained are unique. We cannot assume that they are perfect. We can assume that they are good approaches to the reality, but not accept them with a 100% confidence interval. And this is what statistical inference is about.

Within different approaches we would have probably gotten different results, and that is totally fine. First of all we assumed that our continuous variable "PriceforGermany" followed a normal distribution, despite of when we plotted the original value it looked more like a Gamma distribution. We decided to go with a normal distribution at the end because for our different estimation methods, we obtained better results for the normal distribution. We know that the methods that we learn are not the best ones, but they do their job fine, they are easy to understand and they do not require complex software to solve them, we could have done each calculation by hand and obtain the same results.

Once assumed how was distributed our sample, we got that the sample mean was for the prices in Germany 52.243€ which is quite expensive considering the actual prices for fuel cars. Also, within our analysis we can say with a 95% of confidence that the mean price is in between 21.215€ and 128.643€, which is a very good estimation for the electric car market. 

Also, from the estimated proportion we got with a 95% confidence level that between 19% and 31% of the cars are rear wheel driven. This really surprises us because again compared with traditional cars, it is very rare to find rear wheel cars as they are more difficult to control. Only few several sports brands like BMW and Mercedes-Benz used them in most of their cars.

On what we could call the second part of the project we started doing analysis for a different characteristic (but also a very important one) about the cars, which is the number of seats. We got that the mean prices were not significance different between them, and that also surprised us, as most of the times, big cars (7 seats) are always more likely to be more expensive.

Along all the project we have gotten a lot of different solutions, we have try to solve each point with several different methods and we have ended up showing the ones that we thought will be the better ones for each point and purpose.

## Mention limitations and possible extensions of this project

We have found several limitations in the project and most of them were directly related to the difficulty of obtaining good results with more complex distributions than the normal. For example with the Gamma distribution, we could not come to good results without using numerical methods techniques like for example when we tried to estimate its parameters using Maximum Likelihood method. We had several difficulties while trying to compute the factorial in its pdf.

Another limitation that we found which is more related to our data set is that our sample is not long enough. Even though it has 177 values, it is very difficult to assume that the results obtained were really good estimators about the whole electric car market. Also, due to this limitation when we wanted to divide the sample depending on the number of seats, as we had so few values for some number of seats we had to group them in just two different types.

A very reasonable and logic extension of this project could be the fact about making inference not only in the electric vehicle car market but also in the traditional car market. This way we could obtain good conclusions about the real difference between this two markets. 

Even though there is a lot of information about the automobile industry, it is not easy to find statistics about it. We had some difficulties on one of our main purposes within this project, which was being able to compare between this two markets in order to make assumptions on whether it was a good idea to start considering buying an electric car and find out if their prices were fair or if they were still overvalued.

Despite this we are very proud of the results that we have come to and we really enjoyed working with this data set. Also we have gained a little bit of knowledge about the electric car market, which was our main purpose with this project. Moreover we think that the document is easy enough for everybody to understand it so anyone can also learn with this project.

